{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4845ac3",
   "metadata": {},
   "source": [
    "# Business Default Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4710a2",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e81282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f4925",
   "metadata": {},
   "source": [
    "## Custom layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1_ActivityRegularization(keras.layers.Layer):\n",
    "    \"\"\"Layer that creates an activity sparsity regularization loss.\"\"\"\n",
    "\n",
    "    def __init__(self, rate=1e-2):\n",
    "        super(L1_ActivityRegularization, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # We use `add_loss` to create a regularization loss\n",
    "        # that depends on the inputs.\n",
    "        self.add_loss(self.rate * tf.reduce_sum(tf.math.abs(inputs)))\n",
    "        return inputs\n",
    "\n",
    "class residualBlock(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    y1 = ReLU(w1.x+b1)\n",
    "    y2 = RelU(w2.y1+b2)\n",
    "    y = ReLU(y2+x)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(residualBlock, self).__init__()\n",
    "        self.r1 = L1_ActivityRegularization(1e-3)\n",
    "        self.r2 = L1_ActivityRegularization(1e-3)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.w1 = self.add_weight(\n",
    "            shape=(input_shape[-1], input_shape[-1]),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b1 = self.add_weight(\n",
    "            shape=(input_shape[-1],), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.w2 = self.add_weight(\n",
    "            shape=(input_shape[-1], input_shape[-1]),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b2 = self.add_weight(\n",
    "            shape=(input_shape[-1],), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y1 = self.r1(tf.nn.relu(tf.matmul(inputs, self.w1) + self.b1))\n",
    "        y2 = self.r2(tf.nn.relu(tf.matmul(y1, self.w2) + self.b2))\n",
    "        return tf.nn.relu(y2+inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f019ed",
   "metadata": {},
   "source": [
    "## Declare Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankModel(Model):\n",
    "    def __init__(self,):\n",
    "        super(BankModel, self).__init__()\n",
    "        \n",
    "        # Declare model layers \n",
    "        self.layer_1 = residualBlock()\n",
    "        self.layer_2 = keras.layers.Dense(64, activation=\"relu\")\n",
    "        self.layer_3  = keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "        # Declare loss and metrics\n",
    "        self.loss_cc = tf.keras.losses.CategoricalCrossentropy()\n",
    "        self.acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"List of the model's metrics.\n",
    "        We make sure the loss tracker is listed as part of `model.metrics`\n",
    "        so that `fit()` and `evaluate()` are able to `reset()` the loss tracker\n",
    "        at the start of each epoch and at the start of an `evaluate()` call.\n",
    "        \"\"\"\n",
    "        return [self.loss_tracker,self.acc]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = self.layer_2(x)\n",
    "        y = self.layer_3(x)\n",
    "        return y\n",
    "\n",
    "    def train_step(self, data):\n",
    "        X, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            yh = self.layer_1(X)\n",
    "            yh = self.layer_2(yh)\n",
    "            yh = self.layer_3(yh)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = self.loss_cc(y,yh)\n",
    "            self.loss_tracker.update_state(loss)\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.acc.update_state(y,yh)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value   \n",
    "        results = {\"acc\": self.acc.result()}\n",
    "        results[\"loss\"] = self.loss_tracker.result()\n",
    "        return results\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        X, y = data\n",
    "        \n",
    "        yh = self.layer_1(X)\n",
    "        yh = self.layer_2(yh)\n",
    "        yh = self.layer_3(yh)\n",
    "            \n",
    "        # Compute loss\n",
    "        loss = self.loss_cc(y,yh)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        # Return a dict mapping metric names to current value  \n",
    "        self.acc.update_state(y,yh)\n",
    "        results = {\"acc\": self.acc.result()}\n",
    "        results[\"loss\"] = self.loss_tracker.result()\n",
    "        return results\n",
    "    \n",
    "    def build_graph(self, raw_shape):\n",
    "        x = tf.keras.layers.Input(shape=raw_shape)\n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a778c52",
   "metadata": {},
   "source": [
    "## Load data for testing model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b59aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1868cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32` and flatten.\"\"\"\n",
    "    image = tf.squeeze(tf.cast(image, tf.float32))\n",
    "    return tf.reshape(image,(28*28,)) / 255., tf.one_hot(label,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535254a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(\n",
    "    prep_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(64)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77953f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    prep_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(64)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ds_train.take(1):\n",
    "    X, y = t\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14ad59",
   "metadata": {},
   "source": [
    "## Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c66ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (784,)\n",
    "model = BankModel()\n",
    "model.compile(optimizer=\"rmsprop\")\n",
    "model.build_graph(input_shape).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f348736",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds_train, epochs=5, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b4c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d835f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f341d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ee304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996be0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821fd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cub_data_science",
   "language": "python",
   "name": "cub_data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
