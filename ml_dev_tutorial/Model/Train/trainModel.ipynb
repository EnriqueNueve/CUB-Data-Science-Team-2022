{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb7017d",
   "metadata": {},
   "source": [
    "# Train model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b965c66",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b81462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import datetime\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e47e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "%rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3de906",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd87444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding function\n",
    "def parse_record(record):\n",
    "    name_to_features = {\n",
    "        'features': tf.io.FixedLenFeature([95], tf.float32),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "def decode_record(record):\n",
    "    features = record['features']\n",
    "    target = record['label']\n",
    "    return (features,target)\n",
    "\n",
    "def prepData(record):\n",
    "    record = parse_record(record)\n",
    "    X,y = decode_record(record)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3843417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\"\"\"\n",
    "\n",
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.9, val_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/rick/Desktop/Boulder/Spring2022/data_science/workspace/CUB-Data-Science-Team-2022/ml_dev_tutorial/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name = data_path+\"/tfRecord/train.tfrecord\"\n",
    "train_dataset = tf.data.TFRecordDataset(train_file_name)\n",
    "train_dataset = train_dataset.map(prepData, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(10000)\n",
    "train_dataset = train_dataset.batch(64)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Split train data into train and val \n",
    "train_size = sum(1 for _ in train_dataset)\n",
    "train_dataset, val_dataset = get_dataset_partitions_tf(train_dataset,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name = data_path+\"/tfRecord/test.tfrecord\"\n",
    "test_dataset = tf.data.TFRecordDataset(test_file_name)\n",
    "test_dataset = test_dataset.map(prepData, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.cache()\n",
    "test_dataset = test_dataset.shuffle(10000)\n",
    "test_dataset = test_dataset.batch(64)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train data is feeding right \n",
    "for t in train_dataset.take(1):\n",
    "    X, y  = t\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "# Test test data is feeding right\n",
    "for t in test_dataset.take(1):\n",
    "    X, y  = t\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d4ce3",
   "metadata": {},
   "source": [
    "## Declare model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72329c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1_ActivityRegularization(keras.layers.Layer):\n",
    "    \"\"\"Layer that creates an activity sparsity regularization loss.\"\"\"\n",
    "\n",
    "    def __init__(self, rate=1e-2):\n",
    "        super(L1_ActivityRegularization, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # We use `add_loss` to create a regularization loss\n",
    "        # that depends on the inputs.\n",
    "        self.add_loss(self.rate * tf.reduce_sum(tf.math.abs(inputs)))\n",
    "        return inputs\n",
    "\n",
    "class customDenseLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    y = eLU(w.x+b)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,units):\n",
    "        super(customDenseLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.r = L1_ActivityRegularization(1e-4)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "            name=\"w\"\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True,name=\"b\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y = tf.nn.elu(tf.matmul(inputs, self.w) + self.b)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankModel(Model):\n",
    "    def __init__(self,):\n",
    "        super(BankModel, self).__init__(name=\"bank_model\")\n",
    "        \n",
    "        # Declare model layers \n",
    "        self.layer_1 = customDenseLayer(48)\n",
    "        self.layer_2 = tf.keras.layers.Dropout(.3)\n",
    "        self.layer_3 = layers.Dense(\n",
    "                units=16,\n",
    "                activation=\"elu\",\n",
    "                kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "                bias_regularizer=regularizers.l2(1e-3),\n",
    "                activity_regularizer=regularizers.l2(1e-3)\n",
    "            )\n",
    "        self.layer_4 = tf.keras.layers.Dropout(.3)\n",
    "        self.layer_5 = layers.Dense(\n",
    "                units=1,\n",
    "                activation=\"sigmoid\",\n",
    "            )\n",
    "        \n",
    "        # Declare loss and metrics\n",
    "        self.loss_cc = tf.keras.losses.BinaryCrossentropy()\n",
    "        self.tp = tf.keras.metrics.TruePositives(name='tp')\n",
    "        self.fp = tf.keras.metrics.FalsePositives(name='fp')\n",
    "        self.tn = tf.keras.metrics.TrueNegatives(name='tn')\n",
    "        self.fn = tf.keras.metrics.FalseNegatives(name='fn') \n",
    "        self.acc = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "        self.prec = tf.keras.metrics.Precision(name='precision')\n",
    "        self.rec = tf.keras.metrics.Recall(name='recall')\n",
    "        self.auc = tf.keras.metrics.AUC(name='auc')        \n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"List of the model's metrics.\n",
    "        We make sure the loss tracker is listed as part of `model.metrics`\n",
    "        so that `fit()` and `evaluate()` are able to `reset()` the loss tracker\n",
    "        at the start of each epoch and at the start of an `evaluate()` call.\n",
    "        \"\"\"\n",
    "        return [self.loss_tracker,self.acc,self.rec,self.prec,self.auc,\\\n",
    "                        self.tp,self.fp,self.tn,self.fn]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        yh = self.layer_5(x)\n",
    "        return yh\n",
    "\n",
    "    def train_step(self, data):\n",
    "        X, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            x = self.layer_1(X)\n",
    "            x = self.layer_2(x)\n",
    "            x = self.layer_3(x)\n",
    "            x = self.layer_4(x)\n",
    "            yh = self.layer_5(x)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = self.loss_cc(y,yh)\n",
    "            self.loss_tracker.update_state(loss)\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.acc.update_state(y,tf.math.round(yh))\n",
    "        self.rec.update_state(y,yh)\n",
    "        self.prec.update_state(y,yh)\n",
    "        self.auc.update_state(y,yh)\n",
    "        self.tp.update_state(y,yh)\n",
    "        self.fp.update_state(y,yh)\n",
    "        self.tn.update_state(y,yh)\n",
    "        self.fn.update_state(y,yh)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value   \n",
    "        results = {\"loss\": self.loss_tracker.result()}\n",
    "        results[\"acc\"] = self.acc.result()\n",
    "        results[\"recall\"] = self.rec.result()\n",
    "        results[\"precision\"] = self.prec.result()\n",
    "        results[\"auc\"] = self.auc.result()\n",
    "        results[\"tp\"] = self.tp.result()\n",
    "        results[\"fp\"] = self.fp.result()\n",
    "        results[\"tn\"] = self.tn.result()\n",
    "        results[\"fn\"] = self.fn.result()\n",
    "        return results\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        X, y = data\n",
    "        \n",
    "        x = self.layer_1(X)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        yh = self.layer_5(x)\n",
    "            \n",
    "        # Compute loss\n",
    "        loss = self.loss_cc(y,yh)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.acc.update_state(y,tf.math.round(yh))\n",
    "        self.rec.update_state(y,yh)\n",
    "        self.prec.update_state(y,yh)\n",
    "        self.auc.update_state(y,yh)\n",
    "        self.tp.update_state(y,yh)\n",
    "        self.fp.update_state(y,yh)\n",
    "        self.tn.update_state(y,yh)\n",
    "        self.fn.update_state(y,yh)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value \n",
    "        results = {\"loss\": self.loss_tracker.result()}\n",
    "        results[\"acc\"] = self.acc.result()\n",
    "        results[\"recall\"] = self.rec.result()\n",
    "        results[\"precision\"] = self.prec.result()\n",
    "        results[\"auc\"] = self.auc.result()\n",
    "        results[\"tp\"] = self.tp.result()\n",
    "        results[\"fp\"] = self.fp.result()\n",
    "        results[\"tn\"] = self.tn.result()\n",
    "        results[\"fn\"] = self.fn.result()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def build_graph(self, raw_shape):\n",
    "        x = tf.keras.layers.Input(shape=raw_shape)\n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30579ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bank model object to make standard model object\n",
    "input_shape = ((95,))\n",
    "model = BankModel()\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3))\n",
    "model.build_graph(input_shape).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcf578",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=75, validation_data=val_dataset,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9af36",
   "metadata": {},
   "source": [
    "## Evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(test_dataset,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de8c249",
   "metadata": {},
   "source": [
    "### View tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear logs, remove if you want to save\n",
    "%rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61243025",
   "metadata": {},
   "source": [
    "### Reload test data to convert to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54308a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name = data_path+\"/tfRecord/test.tfrecord\"\n",
    "test_dataset = tf.data.TFRecordDataset(test_file_name)\n",
    "test_dataset = test_dataset.map(prepData, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.cache()\n",
    "test_dataset = test_dataset.shuffle(10000)\n",
    "test_dataset = test_dataset.batch(3000)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(test_dataset)\n",
    "next_element = iterator.get_next()\n",
    "X_test, y_test = next_element\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996724d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = np.round(Y_pred).flatten()\n",
    "target_names = ['no fraud','fraud']\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = pd.DataFrame(cm, range(2),range(2))\n",
    "plt.figure(figsize = (8,8))\n",
    "\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8426147",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR='tf_model'\n",
    "version = \"1\"\n",
    "export_path = os.path.join(MODEL_DIR, str(version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67563c",
   "metadata": {},
   "source": [
    "## Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55691245",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_model = tf.keras.models.load_model('model', custom_objects={'layer_1': customDenseLayer})\n",
    "saved_model = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = saved_model.predict(X_test, verbose=1)\n",
    "y_pred = np.round(Y_pred).flatten()\n",
    "target_names = ['no fraud','fraud']\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7693467",
   "metadata": {},
   "source": [
    "## Make tf lite model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(saved_model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"tflite_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fce5ef",
   "metadata": {},
   "source": [
    "### Test infrence on tf lite on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d76943",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test.numpy()[0,:]\n",
    "x_test = x_test.reshape((1,95))\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tflite_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "#get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "#set the tensor to point to the input data to be inferred\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "interpreter.set_tensor(input_index, x_test)\n",
    "\n",
    "#Run the inference\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbdb671",
   "metadata": {},
   "source": [
    "### Check if performance holds with tf lite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa468ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tflite_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "#get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testLite(x_test):\n",
    "    #set the tensor to point to the input data to be inferred\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    interpreter.set_tensor(input_index, x_test)\n",
    "\n",
    "    #Run the inference\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return output_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751cfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_pred = []\n",
    "for i in range(2046):\n",
    "    x_test = X_test.numpy()[i,:]\n",
    "    x_test = x_test.reshape((1,95))\n",
    "    pred = testLite(x_test)\n",
    "    lite_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72da631",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['no fraud','fraud']\n",
    "print(classification_report(y_test, np.round(lite_pred),target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a3333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29688ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4bbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e404f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f73530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cub_data_science",
   "language": "python",
   "name": "cub_data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
